import streamlit as st
import pandas as pd
import io
import time
from google import genai
from google.genai.errors import APIError

# --- ìƒìˆ˜ ì„¤ì • ---
MODEL_OPTIONS = [
    'gemini-2.0-flash',
    'gemini-2.0-pro',
    'gemini-1.5-flash',
    'gemini-1.5-pro',
]

SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ ì „ë¬¸ ì‹¬ë¦¬ ìƒë‹´ê°€ì…ë‹ˆë‹¤.

1. ì‚¬ìš©ìëŠ” ìì‹ ì´ ê²ªê³  ìˆëŠ” ì‹¬ë¦¬ì ì¸ ê³ ì¶©ì— ëŒ€í•´ì„œ í„¸ì–´ë†“ìŠµë‹ˆë‹¤.
2. ì‚¬ìš©ìì˜ ì‹¬ë¦¬ì ì¸ ë¬¸ì œìš”ì¸ì„ ì •ë¦¬í•˜ê³ , ì´ì— ëŒ€í•´ ì „ë¬¸ì ì¸ ì§€ì‹ì„ í™œìš©í•˜ì—¬, ì‹¬ë¦¬ìƒë‹´ê°€ê°€ í•´ì¤„ ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
3. ë§ˆì§€ë§‰ì—ëŠ” ì´ ìƒë‹´ì€ AIê°€ ë‹µë³€ì„ ì œê³µí•œ ê²ƒìœ¼ë¡œ, ìƒë‹´ ì´í›„ì—ë„ ì‹¬ë¦¬ì  ë¶ˆí¸ì´ í•´ì†Œë˜ì§€ ì•Šì„ ê²½ìš°, ì „ë¬¸ê°€ë¥¼ ì°¾ì•„ ì¹˜ë£Œë°›ì„ ê²ƒì„ ê¶Œì¥í•˜ì„¸ìš”. ì´í›„ ë” í•„ìš”í•œ ì‚¬í•­ì— ëŒ€í•´ì„œ ë¬¼ì–´ë³´ì„¸ìš”.

ë‹µë³€ì€ í¬ë§ê³¼ ì•ˆì •ê°ì„ ì¤„ ìˆ˜ ìˆë„ë¡, ì‚¬ìš©ìë¥¼ ìê·¹í•˜ê±°ë‚˜ íŒë‹¨í•˜ì§€ ì•Šë„ë¡ ê°ë³„íˆ ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤."""

# --- Streamlit ìƒíƒœ ì´ˆê¸°í™” ---
if 'history' not in st.session_state:
    st.session_state['history'] = []
if 'session_id' not in st.session_state:
    st.session_state['session_id'] = f"session_{time.strftime('%Y%m%d%H%M%S')}"
if 'csv_log' not in st.session_state:
    st.session_state['csv_log'] = []

# --- ê¸°ëŠ¥ í•¨ìˆ˜ ì •ì˜ ---
def initialize_client(api_key):
    """Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    try:
        return genai.Client(api_key=api_key)
    except Exception as e:
        st.error(f"í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return None

def reset_conversation():
    """ëŒ€í™” ì´ˆê¸°í™”"""
    st.session_state['history'] = []
    st.session_state['session_id'] = f"session_{time.strftime('%Y%m%d%H%M%S')}"
    st.session_state['csv_log'] = []
    st.rerun()

def call_gemini_api(client, model_name, prompt, max_retries=5):
    """Gemini API í˜¸ì¶œ (429/503 ì¬ì‹œë„ í¬í•¨, ìµœê·¼ 6í„´ íˆìŠ¤í† ë¦¬ ìœ ì§€)"""
    # ìµœê·¼ 6í„´ íˆìŠ¤í† ë¦¬ ì¶”ì¶œ (12ê°œ ë©”ì‹œì§€: user + model ìŒ)
    recent_history = st.session_state['history'][-12:] if len(st.session_state['history']) > 0 else []
    
    # íˆìŠ¤í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    history_context = ""
    for msg in recent_history:
        if msg['role'] == 'user':
            history_context += f"ì‚¬ìš©ì: {msg['text']}\n"
        elif msg['role'] == 'model':
            history_context += f"ìƒë‹´ê°€: {msg['text']}\n"
    
    # ì „ì²´ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + íˆìŠ¤í† ë¦¬ + í˜„ì¬ ë©”ì‹œì§€)
    if history_context:
        full_prompt = f"{SYSTEM_PROMPT}\n\nì´ì „ ëŒ€í™”:\n{history_context}\nì‚¬ìš©ì: {prompt}"
    else:
        full_prompt = f"{SYSTEM_PROMPT}\n\nì‚¬ìš©ì: {prompt}"
    
    for attempt in range(max_retries):
        try:
            # ì„¸ì…˜ ìƒì„± ë° ë©”ì‹œì§€ ì „ì†¡
            chat = client.chats.create(model=model_name)
            response = chat.send_message(full_prompt)
            return response.text
            
        except APIError as e:
            error_msg = str(e)
            # 429 (Rate Limit) ë˜ëŠ” 503 (Service Unavailable) ì˜¤ë¥˜ ì¬ì‹œë„
            if ('429' in error_msg or '503' in error_msg or 'UNAVAILABLE' in error_msg) and attempt < max_retries - 1:
                wait_time = min(2 ** attempt, 10)  # ìµœëŒ€ 10ì´ˆ ëŒ€ê¸° (ì§€ìˆ˜ ë°±ì˜¤í”„)
                st.warning(f"ì„œë²„ ì¼ì‹œì  ì˜¤ë¥˜ ë°œìƒ. {wait_time}ì´ˆ í›„ ì¬ì‹œë„ ì¤‘... ({(attempt + 1)}/{max_retries})")
                time.sleep(wait_time)
                continue
            else:
                st.error(f"API ì˜¤ë¥˜: {error_msg}")
                return f"ì£„ì†¡í•©ë‹ˆë‹¤. API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}"
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = min(2 ** attempt, 5)
                st.warning(f"ì˜¤ë¥˜ ë°œìƒ. {wait_time}ì´ˆ í›„ ì¬ì‹œë„ ì¤‘... ({(attempt + 1)}/{max_retries})")
                time.sleep(wait_time)
                continue
            else:
                st.error(f"ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}")
                return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    return "ì£„ì†¡í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ë²ˆ ì‹œë„í–ˆì§€ë§Œ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

# --- UI ì •ì˜ ---
st.set_page_config(page_title="ì‹¬ë¦¬ìƒë‹´ AI ì±—ë´‡", layout="centered")

st.title("ğŸŒ± ì‹¬ë¦¬ìƒë‹´ AI ì±—ë´‡")
st.caption("ë”°ëœ»í•˜ê³  ì „ë¬¸ì ì¸ ì‹¬ë¦¬ ìƒë‹´ì„ ì œê³µí•©ë‹ˆë‹¤.")

# 1. API í‚¤ ì„¤ì •
api_key = st.secrets.get('GEMINI_API_KEY')
if not api_key:
    st.info("ğŸ”‘ Streamlit Secretsì— 'GEMINI_API_KEY'ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì•„ë˜ì— ì„ì‹œ í‚¤ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    api_key = st.text_input("Gemini API Key", type="password")
    if not api_key:
        st.stop()

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = initialize_client(api_key)
if not client:
    st.stop()

# 2. ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("ì„¤ì • ë° ë„êµ¬")
    
    # ëª¨ë¸ ì„ íƒ
    selected_model = st.selectbox(
        "ì‚¬ìš© ëª¨ë¸ ì„ íƒ",
        MODEL_OPTIONS,
        index=0  # gemini-2.0-flash ê¸°ë³¸ ì„ íƒ
    )
    
    # ëŒ€í™” ì •ë³´
    st.subheader("ëŒ€í™” ì •ë³´")
    st.markdown(f"**ëª¨ë¸:** `{selected_model}`")
    st.markdown(f"**ì„¸ì…˜ ID:** `{st.session_state['session_id']}`")
    st.markdown(f"**ëŒ€í™” í„´ ìˆ˜:** `{len(st.session_state['history']) // 2}`")
    
    # ë¡œê·¸ ë‹¤ìš´ë¡œë“œ
    if st.button("ğŸ’¾ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ (CSV)"):
        if st.session_state['csv_log']:
            df = pd.DataFrame(st.session_state['csv_log'])
            csv_buffer = io.StringIO()
            df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
            st.download_button(
                label="CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=csv_buffer.getvalue(),
                file_name=f"counseling_log_{st.session_state['session_id']}.csv",
                mime="text/csv"
            )
        else:
            st.info("ë‹¤ìš´ë¡œë“œí•  ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ëŒ€í™” ì´ˆê¸°í™”
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", type="primary"):
        reset_conversation()
    
    st.markdown("---")
    st.warning("âš ï¸ ë³¸ ì±—ë´‡ì€ AI ìƒë‹´ì´ë©°, ì‹¬ê°í•œ ì‹¬ë¦¬ì  ë¶ˆí¸ì€ ë°˜ë“œì‹œ ì „ë¬¸ê°€ì™€ ìƒë‹´í•´ì•¼ í•©ë‹ˆë‹¤.")

# 3. ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
for message in st.session_state['history']:
    if 'role' in message and 'text' in message:
        with st.chat_message(message["role"], avatar="ğŸ¤–" if message["role"] == "model" else "ğŸ™‚"):
            st.markdown(message["text"])

# 4. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_prompt := st.chat_input("ë‹¹ì‹ ì˜ ê³ ë¯¼ì„ í¸ì•ˆí•˜ê²Œ í„¸ì–´ë†“ì•„ì£¼ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user", avatar="ğŸ™‚"):
        st.markdown(user_prompt)
    
    # AI ì‘ë‹µ ìƒì„±
    with st.spinner("ì „ë¬¸ì ì¸ ìƒë‹´ ë‹µë³€ì„ ìƒê°í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        model_response = call_gemini_api(client, selected_model, user_prompt)
    
    # AI ì‘ë‹µ í‘œì‹œ
    with st.chat_message("model", avatar="ğŸ¤–"):
        st.markdown(model_response)
    
    # íˆìŠ¤í† ë¦¬ ì €ì¥
    st.session_state['history'].append({"role": "user", "text": user_prompt})
    st.session_state['history'].append({"role": "model", "text": model_response})
    
    # CSV ë¡œê·¸ ê¸°ë¡
    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
    st.session_state['csv_log'].append({
        'session_id': st.session_state['session_id'],
        'model': selected_model,
        'timestamp': timestamp,
        'role': 'user',
        'message': user_prompt
    })
    st.session_state['csv_log'].append({
        'session_id': st.session_state['session_id'],
        'model': selected_model,
        'timestamp': timestamp,
        'role': 'model',
        'message': model_response
    })
    
    # UI ì—…ë°ì´íŠ¸
    st.rerun()
